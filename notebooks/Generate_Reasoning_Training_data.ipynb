{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33e4e0f-c631-46d0-b79e-58744cd3e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "@dataclass\n",
    "class Topic:\n",
    "    name: str\n",
    "    subtopics: List[str]\n",
    "\n",
    "class TopicParser:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        \n",
    "    def parse_topics(self) -> List[Topic]:\n",
    "        \"\"\"Parse the text into a list of Topic objects.\"\"\"\n",
    "        # Split the text into sections based on \"**Topic**:\"\n",
    "        sections = re.split(r'(?=\\*\\*[^*]+\\*\\*:)', self.text)\n",
    "        \n",
    "        topics = []\n",
    "        for section in sections:\n",
    "            if not section.strip():\n",
    "                continue\n",
    "                \n",
    "            # Extract topic name\n",
    "            topic_match = re.match(r'\\*\\*([^*]+)\\*\\*:', section)\n",
    "            if not topic_match:\n",
    "                continue\n",
    "                \n",
    "            topic_name = topic_match.group(1).strip()\n",
    "            \n",
    "            # Extract bullet points\n",
    "            subtopics = re.findall(r'-\\s*(.+?)(?=(?:-|\\Z))', section, re.DOTALL)\n",
    "            subtopics = [st.strip() for st in subtopics if st.strip()]\n",
    "            \n",
    "            topics.append(Topic(name=topic_name, subtopics=subtopics))\n",
    "            \n",
    "        return topics\n",
    "\n",
    "@dataclass\n",
    "class GeneratedProblem:\n",
    "    topic: str\n",
    "    subtopics: List[str]\n",
    "    prompt: str\n",
    "    response: str\n",
    "    timestamp: str\n",
    "    model: str\n",
    "\n",
    "class ProblemGenerator:\n",
    "    def __init__(self, llm_client, output_file: Path):\n",
    "        self.llm_client = llm_client\n",
    "        self.output_file = output_file\n",
    "        \n",
    "    async def generate_problems(self, topic: Topic, num_problems: int = 3) -> GeneratedProblem:\n",
    "        \"\"\"Generate problems for a given topic using the LLM and save to JSONL.\"\"\"\n",
    "        prompt = f\"\"\"Create {num_problems} challenging problems for the topic '{topic.name}' \n",
    "        based on these subtopics: {', '.join(topic.subtopics)}\n",
    "        \n",
    "        Each problem should:\n",
    "        1. Test deep understanding rather than memorization\n",
    "        2. Require integration of multiple concepts\n",
    "        3. Have real-world applications where possible\n",
    "        4. Include step-by-step solutions\n",
    "        \n",
    "        Format each problem as:\n",
    "        Problem #: [Problem text]\n",
    "        Solution: [Detailed solution]\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm_client.generate(prompt)\n",
    "        \n",
    "        # Create problem record\n",
    "        problem = GeneratedProblem(\n",
    "            topic=topic.name,\n",
    "            subtopics=topic.subtopics,\n",
    "            prompt=prompt,\n",
    "            response=response,\n",
    "            timestamp=datetime.utcnow().isoformat(),\n",
    "            model=self.llm_client.model_name\n",
    "        )\n",
    "        \n",
    "        # Save to JSONL file\n",
    "        with self.output_file.open('a', encoding='utf-8') as f:\n",
    "            json.dump(asdict(problem), f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "            \n",
    "        return problem\n",
    "\n",
    "async def main(text_content: str, llm_client, output_file: Path) -> Dict[str, List[GeneratedProblem]]:\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Parse topics\n",
    "    parser = TopicParser(text_content)\n",
    "    topics = parser.parse_topics()\n",
    "    \n",
    "    # Initialize problem generator\n",
    "    generator = ProblemGenerator(llm_client, output_file)\n",
    "    \n",
    "    # Generate problems for each topic concurrently\n",
    "    async def process_topic(topic: Topic) -> Tuple[str, List[GeneratedProblem]]:\n",
    "        problem = await generator.generate_problems(topic)\n",
    "        return (topic.name, [problem])\n",
    "    \n",
    "    tasks = [process_topic(topic) for topic in topics]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Organize results\n",
    "    problem_database = dict(results)\n",
    "    \n",
    "    return problem_database\n",
    "    \n",
    "    # Generate problems for each topic concurrently\n",
    "    async def process_topic(topic: Topic) -> Tuple[str, List[str]]:\n",
    "        problems = await generator.generate_problems(topic)\n",
    "        return (topic.name, problems)\n",
    "    \n",
    "    tasks = [process_topic(topic) for topic in topics]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Organize results\n",
    "    problem_database = {}\n",
    "    for topic_name, problems in results:\n",
    "        problem_database[topic_name] = problems\n",
    "        \n",
    "    return problem_database\n",
    "\n",
    "# Example usage:\n",
    "class OllamaClient:\n",
    "    def __init__(self, model_name: str = \"mistral\", base_url: str = \"http://100.65.190.72:11434\", timeout: int = 120):\n",
    "        self.model_name = model_name\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.timeout = timeout\n",
    "        \n",
    "    async def generate(self, prompt: str) -> str:\n",
    "        \"\"\"Generate text using Ollama API.\"\"\"\n",
    "        import aiohttp\n",
    "        import json\n",
    "        from aiohttp import ClientTimeout\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        timeout = ClientTimeout(total=self.timeout)\n",
    "        \n",
    "        try:\n",
    "            async with aiohttp.ClientSession(timeout=timeout) as session:\n",
    "                async with session.post(f\"{self.base_url}/api/generate\", json=payload) as response:\n",
    "                    if response.status != 200:\n",
    "                        error_text = await response.text()\n",
    "                        raise Exception(f\"Ollama API error {response.status}: {error_text}\")\n",
    "                    \n",
    "                    response_text = await response.text()\n",
    "                    try:\n",
    "                        response_json = json.loads(response_text)\n",
    "                        return response_json.get('response', '')\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        raise Exception(f\"Failed to parse Ollama response: {e}\\nResponse text: {response_text}\")\n",
    "                        \n",
    "        except aiohttp.ClientError as e:\n",
    "            raise Exception(f\"Failed to connect to Ollama server: {e}\")\n",
    "        except asyncio.TimeoutError:\n",
    "            raise Exception(f\"Request timed out after {self.timeout} seconds\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Unexpected error while calling Ollama: {e}\")\n",
    "            \n",
    "    async def check_model_availability(self) -> bool:\n",
    "        \"\"\"Check if the specified model is available in Ollama.\"\"\"\n",
    "        import aiohttp\n",
    "        \n",
    "        try:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.get(f\"{self.base_url}/api/tags\") as response:\n",
    "                    if response.status != 200:\n",
    "                        return False\n",
    "                    \n",
    "                    data = await response.json()\n",
    "                    available_models = [model['name'] for model in data.get('models', [])]\n",
    "                    return self.model_name in available_models\n",
    "                    \n",
    "        except Exception:\n",
    "            return False\n",
    "            \n",
    "    async def validate_connection(self) -> bool:\n",
    "        \"\"\"Validate connection to Ollama server.\"\"\"\n",
    "        import aiohttp\n",
    "        \n",
    "        try:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.get(f\"{self.base_url}/api/version\") as response:\n",
    "                    return response.status == 200\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "\n",
    "# Helper function to save results to a file\n",
    "def save_problems_to_file(problem_database: Dict[str, List[str]], filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for topic, problems in problem_database.items():\n",
    "            f.write(f\"\\n\\n{'='*50}\\n{topic}\\n{'='*50}\\n\")\n",
    "            for i, problem in enumerate(problems, 1):\n",
    "                f.write(f\"\\nProblem {i}:\\n{problem}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e88a8d-b14f-464e-96f5-caaaea0bc050",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Failed to connect to Ollama server: Cannot connect to host localhost:11434 ssl:default [Connect call failed ('127.0.0.1', 11434)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/connector.py:980\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[0;34m(self, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m ceil_timeout(timeout\u001b[38;5;241m.\u001b[39msock_connect):\n\u001b[0;32m--> 980\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_connection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[return-value]  # noqa\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cert_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/news_env/lib/python3.10/asyncio/base_events.py:1070\u001b[0m, in \u001b[0;36mBaseEventLoop.create_connection\u001b[0;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname, ssl_handshake_timeout, happy_eyeballs_delay, interleave)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(exceptions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;66;03m# If they all have the same str(), raise one.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/news_env/lib/python3.10/asyncio/base_events.py:1054\u001b[0m, in \u001b[0;36mBaseEventLoop.create_connection\u001b[0;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname, ssl_handshake_timeout, happy_eyeballs_delay, interleave)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1054\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_sock(\n\u001b[1;32m   1055\u001b[0m         exceptions, addrinfo, laddr_infos)\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/news_env/lib/python3.10/asyncio/base_events.py:963\u001b[0m, in \u001b[0;36mBaseEventLoop._connect_sock\u001b[0;34m(self, exceptions, addr_info, local_addr_infos)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m my_exceptions\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m--> 963\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock_connect(sock, address)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "File \u001b[0;32m~/anaconda3/envs/news_env/lib/python3.10/asyncio/selector_events.py:501\u001b[0m, in \u001b[0;36mBaseSelectorEventLoop.sock_connect\u001b[0;34m(self, sock, address)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;66;03m# Needed to break cycles when an exception occurs.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/news_env/lib/python3.10/asyncio/selector_events.py:541\u001b[0m, in \u001b[0;36mBaseSelectorEventLoop._sock_connect_cb\u001b[0;34m(self, fut, sock, address)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;66;03m# Jump to any except clause below.\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(err, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnect call failed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mBlockingIOError\u001b[39;00m, \u001b[38;5;167;01mInterruptedError\u001b[39;00m):\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;66;03m# socket is still registered, the callback will be retried later\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connect call failed ('127.0.0.1', 11434)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mClientConnectorError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 155\u001b[0m, in \u001b[0;36mOllamaClient.generate\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aiohttp\u001b[38;5;241m.\u001b[39mClientSession(timeout\u001b[38;5;241m=\u001b[39mtimeout) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m=\u001b[39mpayload) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/client.py:1141\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[0;32m-> 1141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/client.py:536\u001b[0m, in \u001b[0;36mClientSession._request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx, read_bufsize)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m         conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[1;32m    537\u001b[0m             req, traces\u001b[38;5;241m=\u001b[39mtraces, timeout\u001b[38;5;241m=\u001b[39mreal_timeout\n\u001b[1;32m    538\u001b[0m         )\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/connector.py:540\u001b[0m, in \u001b[0;36mBaseConnector.connect\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(req, traces, timeout)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/connector.py:901\u001b[0m, in \u001b[0;36mTCPConnector._create_connection\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     _, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_direct_connection(req, traces, timeout)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proto\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/connector.py:1206\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[0;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m last_exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1206\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m last_exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/connector.py:1175\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[0;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     transp, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_create_connection(\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_factory,\n\u001b[1;32m   1177\u001b[0m         host,\n\u001b[1;32m   1178\u001b[0m         port,\n\u001b[1;32m   1179\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1180\u001b[0m         ssl\u001b[38;5;241m=\u001b[39msslcontext,\n\u001b[1;32m   1181\u001b[0m         family\u001b[38;5;241m=\u001b[39mhinfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1182\u001b[0m         proto\u001b[38;5;241m=\u001b[39mhinfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproto\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1183\u001b[0m         flags\u001b[38;5;241m=\u001b[39mhinfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1184\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mhinfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhostname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m sslcontext \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1185\u001b[0m         local_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_addr,\n\u001b[1;32m   1186\u001b[0m         req\u001b[38;5;241m=\u001b[39mreq,\n\u001b[1;32m   1187\u001b[0m         client_error\u001b[38;5;241m=\u001b[39mclient_error,\n\u001b[1;32m   1188\u001b[0m     )\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientConnectorError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/aiohttp/connector.py:988\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[0;34m(self, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 988\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m client_error(req\u001b[38;5;241m.\u001b[39mconnection_key, exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mClientConnectorError\u001b[0m: Cannot connect to host localhost:11434 ssl:default [Connect call failed ('127.0.0.1', 11434)]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m llm_client \u001b[38;5;241m=\u001b[39m OllamaClient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-r1:32b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Run async code directly with await\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m problem_database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main(text_content, llm_client, output_file)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Print results summary\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerated problems for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(problem_database)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m topics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 110\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(text_content, llm_client, output_file)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (topic\u001b[38;5;241m.\u001b[39mname, [problem])\n\u001b[1;32m    109\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [process_topic(topic) \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m topics]\n\u001b[0;32m--> 110\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Organize results\u001b[39;00m\n\u001b[1;32m    113\u001b[0m problem_database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(results)\n",
      "Cell \u001b[0;32mIn[4], line 106\u001b[0m, in \u001b[0;36mmain.<locals>.process_topic\u001b[0;34m(topic)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_topic\u001b[39m(topic: Topic) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, List[GeneratedProblem]]:\n\u001b[0;32m--> 106\u001b[0m     problem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m generator\u001b[38;5;241m.\u001b[39mgenerate_problems(topic)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (topic\u001b[38;5;241m.\u001b[39mname, [problem])\n",
      "Cell \u001b[0;32mIn[4], line 74\u001b[0m, in \u001b[0;36mProblemGenerator.generate_problems\u001b[0;34m(self, topic, num_problems)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"Generate problems for a given topic using the LLM and save to JSONL.\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCreate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_problems\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m challenging problems for the topic \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124mbased on these subtopics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(topic\u001b[38;5;241m.\u001b[39msubtopics)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124mSolution: [Detailed solution]\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_client\u001b[38;5;241m.\u001b[39mgenerate(prompt)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Create problem record\u001b[39;00m\n\u001b[1;32m     77\u001b[0m problem \u001b[38;5;241m=\u001b[39m GeneratedProblem(\n\u001b[1;32m     78\u001b[0m     topic\u001b[38;5;241m=\u001b[39mtopic\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     79\u001b[0m     subtopics\u001b[38;5;241m=\u001b[39mtopic\u001b[38;5;241m.\u001b[39msubtopics,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_client\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[1;32m     84\u001b[0m )\n",
      "Cell \u001b[0;32mIn[4], line 168\u001b[0m, in \u001b[0;36mOllamaClient.generate\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse Ollama response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResponse text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m aiohttp\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to connect to Ollama server: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Failed to connect to Ollama server: Cannot connect to host localhost:11434 ssl:default [Connect call failed ('127.0.0.1', 11434)]"
     ]
    }
   ],
   "source": [
    "# Example text content\n",
    "text_content = \"\"\"\n",
    "**Mathematics**:\n",
    "- Advanced calculus problems involving multivariable functions.\n",
    "- Complex algebraic structures like abstract group theory.\n",
    "\"\"\"\n",
    "\n",
    "# Assuming your topics are in text_content\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize client and set output path\n",
    "output_file = Path('output/problems.jsonl')\n",
    "llm_client = OllamaClient(\"deepseek-r1:32b\")\n",
    "\n",
    "# Run async code directly with await\n",
    "problem_database = await main(text_content, llm_client, output_file)\n",
    "\n",
    "# Print results summary\n",
    "print(f\"\\nGenerated problems for {len(problem_database)} topics:\")\n",
    "for topic, problems in problem_database.items():\n",
    "    print(f\"- {topic}: {len(problems)} problems\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c80b7-64ba-434e-8c4f-5ef5221ad118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_env",
   "language": "python",
   "name": "news_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
