Using device: cuda
Found 1 files
Total tokens: 338026
/home/alexander/Projects/financial_projects/reasonable/train.py:227: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
Epoch 1:   1%|█▎                                                                                                                   | 886/75826 [00:57<1:20:22, 15.54it/s, loss=3.5632, avg_loss=4.5946, lr=3.00e-04]
Traceback (most recent call last):
  File "/home/alexander/Projects/financial_projects/reasonable/train.py", line 237, in <module>
    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, device, epoch)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alexander/Projects/financial_projects/reasonable/train.py", line 44, in train_one_epoch
    scaler.scale(loss).backward()
  File "/home/alexander/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/alexander/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/alexander/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
